---
title: "Dataset description"
# output: html_document
output: 
  bookdown::word_document2:
    reference_docx: resources/styles_template.docx
    number_sections: true
params:
  echo: False
bibliography: resources/bib.bibtex
---

```{r include=FALSE}
knitr::opts_chunk$set(message = F, warning = F, echo=params$echo, fig.width = 4, fig.height = 2)
```


<!-- TODO: *W części 03 przydadzą się ilustracje jak wygląda zbiór danych, statystyki zmiennych etc + solidne mapowanie. Rzeczywiście ostatnia mapa chyba ciekawiej może wyglądać jako grid (dałabym obie). Zupełnie brakuje prostych statystyk sprzedażowych zwizualizowanych na mapie (jako grid): ilu klientów, ile transakcji, wartość transakcji - w ujęciu nominalnym, ale też w odniesieniu do populacji (żeby lepiej rozumieć rozkład transakcji i klientów) + jego density (w gglot można zrobić kernel density punktów i zmapować).* -->

## Olist

TODO: Opis firmy w oderwaniu od datasetu, zamienić podpunkty na paragraf

- (https://www.kaggle.com/olistbr/brazilian-ecommerce access 14.03.2020)
- Brazilian company
- The dataset was published by the company for public use
- Contains information about 100 thousand orders made on the e-commerce shop site from 2016 to 2018
- Very rich dataset - contains information about the order, customer and review

In particular, there were 96180 transactions (96%) from the customers that never previously bought in this shop. 

In this study I am mostly interested in analysing these transactions, and trying to predict just after first transaction, if the customer is likely to buy second time. Changing the customer attitude after buying for the second time is out of the scope of this study. One reason is the lack of data to properly conduct modeling. The other is that usually making customer buy for the second time is the hardest. In particular in this e-commerce store, in the group of the customers that bought for the first time, only 3.2% of them will buy for the second time. However, in the group of the customers that already bought for the second time, 8.6% will buy third time. The same measure is 18.7% for going from third to fourth time. This is a proof that the very first step of retaining the customer is the most important one, and further it is easier and easier to stop the churn.

The primary key in the dataset in the case of almost all features is order number. However, as in the final dataset I'm including the full information only about the first order of each customer, one observation is equal both to one order and one customer. 

The Olist dataset has the following features groups:

- payment value transportation value - value of the order in Brazilian Reals excluding the transportation cost
- number of items the customer bought in particular order
- review of the order - after the finished order the customer can provide the review of the order in 2 forms - 1-5 score or textual review. In the dataset codebook the authors stated that not all of the customers in real life put any review, but this dataset was sampled in such a way that the records without 1-5 review were excluded. On the contrary, the textual review is filled only in ~50%. The data about 1-5 review can be included to the models as-is. Textual review requires however more intense preprocessing, which is described in the *methods* section of this study.
- location of the customer - the main table containing customer information contains 5-digit ZIP code of the customer's home. The company provided also a mapping table, in which each ZIP code is assigned to multiple latitude/longitude coordinates. Probably this was done because of anonimisation reasons - so that one cannot connect the customer from the dataset with the exact house location. To obtain an exact one-to-one customer-geolocation mapping, to each zip code, I have assigned the most central geolocation from the mapping table. To obtain the most central point, I have used Clustering Around Medoids algorithm with only one cluster, and ran the algorithm separately for each ZIP code. 
- products bought - the dataset contains information about how many items there were in the package, as well as product category of each item - in the form of raw text. In total there were 74 categories, but the top 15 accounted for 80% of all the purchases. To limit the number of the variables for the modeling process, I have decided to change the label of all the least popular categories to "others".

## SIDRA

The dataset about the population statistics was obtained from Instituto Brasileiro de Geografia e Estatística web service called SIDRA (https://sidra.ibge.gov.br/tabela/3548 access 26.09.2020). In this study I have used the data obtained from 2010 general census. The dataset is avaliable in aggregation to microregions (a Brasilian administrative unit, it has similar level of aggregation to NUTS 3 european classification). 558 microregions were avaliable. In particular, I have chosen the following 36 variables from the dataset:

- total population of the microregion - 1 variable
- age structure - percentage of people in particular age bin (with the width of the bins equal to 5 years) - 20 variables
- percentage of people living in rural areas and urban areas - 2 variables
- percentage of immigrants compared to total microregion population - 1 variable
- earnings structure - share of the people that earn between x0\*minimum_wage and x1\*minimum_wage - 11 variables

## EDA

```{r cache=F}
library(readr)
library(tidyverse)
library("leaflet")
library(psych)
library(lubridate)
library(cluster)
library(factoextra)
library(caret)
library(rpart)
library(DALEX)
library(stringr)
library(sf)
library(tmap)
library(here)
library(readxl)
```

```{r}
custom_theme <- theme(axis.title = element_text(size=9),
        legend.title = element_text(size=9)
  )
```


```{r cache=T}
load(here('run_all_models_cache/to_model_train.Rdata'))
load(here('run_all_models_cache/to_model_test.Rdata'))
  
vars_basic <- c("payment_value", "review_score", "geolocation_lat", 
                "geolocation_lng",
                "no_items", "sum_freight")

df <- to_model_train[c(vars_basic, 'if_second_order')]
```

#### Statistics in a table

```{r cache=T, caption='aaa'}
summarise_numeric_custom <- function(x){
  
  list(
    "min" = min(x, na.rm = TRUE),
    "Q1" = quantile(x, 0.25, na.rm = TRUE),
    "median" = quantile(x, 0.5, na.rm = TRUE),
    "mean" = mean(x, na.rm = TRUE),
    "Q3" = quantile(x, 0.75, na.rm = TRUE),
    "max" = max(x, na.rm = TRUE)
  ) %>% 
    as_tibble() %>%
    mutate_all(round,2)
}

df %>%
  select_if(is.numeric) %>%
  map_df(~summarise_numeric_custom(.)) -> stats_table

stats_table$Variable = df %>%select_if(is.numeric) %>% names
stats_table <- stats_table %>% select(Variable, everything())
# stats_table %>%
#   flextable::flextable() %>%
#   flextable::set_caption("mtcars data")#, autonum = autonum)

stats_table %>%
  flextable::flextable() %>%
  flextable::set_caption("Basic statistics") %>%
  flextable::font(fontname = 'Times New Roman', part = 'all') %>%
  flextable::fontsize(size = 12) %>%
  flextable::autofit()

```

TODO: opisać? Czy do appendixa??

#### if_second_order 

TODO: wkleić te info gdzieś do tekstu o sidra

- że 97% (?) klientów nie kupuje drugi raz
- że 50% klientów kupuje max do miesiąca po ostatnim zakupie (tabela z kwantylami?)


#### Payment value

On the plot \@ref(fig:payment) the values of payment for each order are presented.  I have used the Kernel Density Estimation technique to smoothen the plot. As the distribution is highly right-skewed, I have logarithmed the values. The density plot is grouped by the fact whether the particular customer also created a second order later. It can be seen that the 2 densities almost overlap. This means that payment value would not be a good predictor in an univariate approach - although maybe it can be interacted with other features and start having predictive power.


```{r payment, cache=T, fig.cap='aaa'}
df %>% 
  ggplot(aes(x =payment_value, fill= if_second_order)) +
  geom_density(alpha=0.5) +
  scale_x_log10() +
  custom_theme
```

#### Review score

On the plot .. percentages of orders that were given x stars in the review are shown. On the right subplot percentages of the customers that made a second order are presented. Most of the reviews are positive - the scores 4 and 5 make up for 75% of the whole dataset. Another thing worth noticing is the tendency to the negative score polarization - if the customer is unsatisfied with the order, it is more likely for her to give the lowest review. 

The Relationship between making a second order and review score for the first one is somehow surprising. One would expect that if the client is unsatisfied for the first time, she will never buy in this store again. In the case of this dataset it is the opposite - the customers that gave one-star review are also the most likely to make the second order. It is worth noting is that the differences between the groups are very small - between 2.9% for review 4 (smallest one), and 3.45% for review 1. One can wonder if this can come simply from random reasons, and that the review score does not influence the probability to come back at all. In particular, the difference between the percentages for the scores 1 and 5 (0.003%) is that small that it most likely for random reasons.

One should bear in mind that the observations avaliable in the dataset are not the complete customers data that the Olist company has. Rather, they were somehow sampled. The dataset authors claim that it represents the customers base in a complete manner. However, there was some sampling bias introduced while creating the dataset that is based on the value of the review score. Namely, in real life case customers do not have to provide star review of every order. The authors of the dataset sampled the orders database in such a way that they excluded the orders, for which the review was not given. One should bear in mind that the analysis of review score is incomplete because of that - one would wonder if there are factors that influence the customer to provide the review, and the very fact of providing the review changes the probability to buy for the second time for that particular customer.

```{r cache=T}

df %>%
  filter(if_second_order=='yes') %>%
  group_by(review_score) %>%
  tally(name = 'cnt_second_order') -> tmp1


ggplot(df, aes(x = review_score)) +
  geom_bar(aes(y = (..count..)/sum(..count..))) +
  labs(y = 'Percentage') + coord_flip() +
  custom_theme -> pl1


df %>% 
  group_by(review_score) %>%
  tally() %>%
  left_join(tmp1) %>%
  mutate(percent_second_order = cnt_second_order/n) %>%
  ggplot(aes(x = review_score, y = percent_second_order)) +
  geom_col() +
  coord_flip() +
  custom_theme -> pl2

gridExtra::grid.arrange(pl1, pl2, ncol=2)


```

#### Items - numbers and percentage

On the plot .. analysis of number of items in the order is presetned. There were also orders with number of items above 6, however they make up for 0.2% of the dataset only, that is why I excluded them for clarity of the plot. On the left subplot is shown the percentage share in the full dataset, while on the right one - percentage of the customers that put second order after ordering x items for the first time.

A trend is clearly visible - the more items the customer has bought in the first order, the more likely she is to also put the second order. This difference is pretty strong - between 1 and 6 items the percentage increase in the response is almost 150%. However, one should bear in mind that big orders are extremely rare - 93% of the customers buy one or two items only. 

```{r cache=T}
# less than 7 - 99.7% of orders
ggplot(df %>% filter(no_items<7), aes(x = no_items)) +
  geom_bar(aes(y = (..count..)/sum(..count..))) +
  labs(y = 'Percentage') +
  scale_x_reverse()+
  coord_flip() +
  custom_theme -> pl1

df %>%
  filter(if_second_order=='yes') %>%
  group_by(no_items) %>%
  tally(name = 'cnt_second_order') -> tmp2

df %>% 
  group_by(no_items) %>%
  tally() %>%
  left_join(tmp2) %>%
  mutate(percent_second_order = cnt_second_order/n) %>%
  filter(no_items<7) %>%
  ggplot(aes(x = no_items, y = percent_second_order)) +
  geom_col() +
  scale_x_reverse()+
  coord_flip() +
  custom_theme -> pl2

gridExtra::grid.arrange(pl1, pl2, ncol=2)


```

#### Transportation cost  

Sum of the final transportation costs that the customer had to make. The distribution is highly right-skewed, so for clarity I have log-transformed the values. 

No clear distinction between two groups of observations are apparent. 

An interesting thing to check is the relationship between the value of the ordered products and the transportation cost. Pearson correlation between these two is 0.5, meaning that the value of the items ordered somehow influences the rest of the costs.

```{r cache=T}
df %>% 
  ggplot(aes(x = sum_freight, fill=if_second_order)) +
  geom_density(alpha=0.5) +
  scale_x_log10() +
  custom_theme
```


#### Maps

<!-- ![](resources/brazil_population_density.png){width=4, height=2} -->

```{r out.width=300, out.height=300}
knitr::include_graphics("resources/brazil_population_density.png")
```

On the picture .., map of Brazil population density is presented (source: https://www.gifex.com/detail2-en/2018-12-15-15407/Population_density_of_Brazil.html). The most densely populated areas are located in souther part of the country. There also the biggest cities like São Paulo and Rio de Janeiro are located. Another populated area is on the eastern coast. North-western part of the country is the least populated. The distribution of the customers (as expected) follows this density, that is why I did not include the map of customers density. 


```{r cache=T}


tmap_mode("plot")
brazil_map <- brazilmaps::get_brmap("Brazil")

df = df[df$geolocation_lat <= 5.27438888,]
df = df[df$geolocation_lng >= -73.98283055,]
df = df[df$geolocation_lat >= -33.75116944,]
df = df[df$geolocation_lng <=  -34.79314722,]


df_map <- sf::st_as_sf(df %>% sample_n(10000), coords = c(4,3))
df_map <- sf::st_as_sf(df, coords = c(4,3))
st_crs(df_map) <- st_crs(brazil_map)

df_map %>%
  mutate(size=ifelse(if_second_order=='yes', 1, 0.4)) -> df_map
```

```{r}
# Load the cities coords

brasil_cities_coords <- read_excel(here("data/brasil_cities_coords.xlsx"))
brasil_cities_coords <- brasil_cities_coords %>%
  select(city, lat, lng, population)


brasil_cities_coords <- sf::st_as_sf(brasil_cities_coords, coords = c(3,2))
st_crs(brasil_cities_coords) <- st_crs(brazil_map)

```

```{r cache=T}
tm_shape(brazil_map) +
  tm_polygons(col = "white") +
  tm_shape(df_map %>% filter(if_second_order!='yes')) +
  tm_symbols(size = 0.1,
             col = "if_second_order",
             palette = RColorBrewer::brewer.pal(3, 'Dark2')[1:2],
             # palette = c('red', ''),
             # style = "fixed",
             # breaks = c(45, 60, 75, 90),
             border.lwd = NA,
             alpha = 0.5)+
  tm_shape(df_map %>% filter(if_second_order=='yes')) +
  tm_symbols(size = 0.1,
             col = "if_second_order",
             palette = RColorBrewer::brewer.pal(3, 'Dark2')[2],
             # palette = c('red', ''),
             # style = "fixed",
             # breaks = c(45, 60, 75, 90),
             border.lwd = NA,
             alpha = 0.5)
```



```{r cache=T}
# prepare dataset

load(here('data/preprocessed/spatial_all.Rdata'))
# microregion_map <- brazilmaps::get_brmap("City")
load(file=here('data/microregion_map.Rdata'))

microregion_map = st_transform(microregion_map, 4326)

microregion_map1 = st_transform(microregion_map, st_crs(df_map))


# Punkt - region
intersection <- st_intersection(y = microregion_map1 %>% select(MicroRegion) , x = df_map)

# statsy per region
intersection %>%
  st_set_geometry(NULL) %>%
  group_by(MicroRegion) %>%
  summarise(
    no_customers = n(),
    mean_payment_value = mean(payment_value),
    sum_payment_value = sum(payment_value),
    median_payment_value = median(payment_value),
    mean_review_score = mean(review_score)
  ) -> stats_per_microregion


intersection %>%
  st_set_geometry(NULL) %>%
  group_by(MicroRegion, if_second_order) %>%
  filter(if_second_order=='yes') %>%
  tally(name = 'cnt_second_order') %>%
  select(-if_second_order) -> tmp_cnt_second_order


stats_per_microregion %>%
  left_join(tmp_cnt_second_order) %>%
  mutate(
    cnt_second_order = coalesce(cnt_second_order, 0),
    percent_second_order = cnt_second_order/no_customers     
         ) %>%
  left_join(spatial_all %>% select(microregion_code, total_pop), 
            by = c('MicroRegion'='microregion_code')) %>%
  mutate(no_customers_per_10000_pop = no_customers/(total_pop/10000)) -> stats_per_microregion2

microregion_map %>%
  left_join(stats_per_microregion2) %>%
  filter(no_customers>5) -> stats_per_microregion3 # TODO: zastanowić się czy ma sens usuwanie regionów o mniej niż x klientów - zaburza obraz (??)

tmap_mode(mode = c("plot"))
```

```{r cache = T}
# Function to plot the map with the same layout and colors
plot_map <- function(variable, title){
  tm_shape(brazil_map) +
    tm_borders()+
    tm_shape(stats_per_microregion3) +
    tm_polygons(col = variable,border.alpha = 0) +
    tm_shape(brasil_cities_coords %>% arrange(-population) %>% head(10)) +
    tm_symbols(size = 0.2,
               col = "black",
               # style = "fixed",
               # breaks = c(45, 60, 75, 90),
               border.lwd = NA,
               alpha = 0.8) +
    tm_text(text='city', just='top',size = 0.8) +
    tm_layout(title= title, title.size = 0.9)
}

w1 <- plot_map('no_customers_per_10000_pop', 'No. customers per 10 thousand inhabitants')
w2 <- plot_map('mean_review_score', 'Mean review score')
w3 <- plot_map('percent_second_order', 'Percentage of customers that placed second order')
w4 <- plot_map('mean_payment_value', 'Mean payment value')
```

```{r cache = T, fig.width=9, fig.height=7}
tmap_arrange(w1, w2, w3, w4, nrow=2)
```

On the figure .., basic statistics about spatial distribution of the features are presented - in aggregation to microregion level. Such binning is relatively coarse - because of that, some of the statistics can be not reliable in the regions with a very small number of customers. That is why I have decided to remove from the map these microregions, in which number of customers was less than 5. Because of hight correlation between number of customers in the region and total population (~93%), a more meaningful statistic than total number of customers is the number of customers per 10 thousand of inhabitants. It is presented on the plot .. . It is visible that bigger shares of customers appear in the southern part of the country, concentrated in the triangle between São Paulo, Rio de Janeiro and Belo Horizonte agglomerations. 

Mean transaction value is bigger in the northern, more desolated part of Brazil. One explanation could be that in these parts deliveries of the packages are more complicated/expensive/take more time, and thus the customers are more eager to place one bigger order than few small ones. Other possibility is that in the northern part the competition between e-commerce sites is smaller, and thus the customers are pushed to buiyng more items at one supplier. 

It is could be argued that in the northern part of the country the people that placed second order are a bit higher. However, this relationship is rather weak. Similar things can be said about mean review score - there is no clear pattern visible.

TODO: Dalsze mapy raczej do wyrzucenia, wprost wynikają z gęstości populacji ??

Number of customers 

wprost wynika z gęstości populacji (korelacja 0.93), raczej do wyrzucenia 

```{r cache=T}
tm_shape(brazil_map) +
  tm_borders()+
  tm_shape(stats_per_microregion3) +
  tm_polygons(col = "no_customers",border.alpha = 0)

```

KDE of customers

```{r}
st_coordinates(df_map) %>% 
  as_tibble() %>%
  # sample_frac(0.1) %>%
  ggplot(aes(x=X, y=Y)) +
  geom_density2d_filled(alpha = 0.7) +
  geom_point(size=0.05) +
  theme_minimal() +
  custom_theme
```

prawie nic nie widać, raczej do wyrzucenia (??)

Total transactions value

```{r cache=T}
tm_shape(brazil_map) +
  tm_borders()+
  tm_shape(stats_per_microregion3) +
  tm_polygons(col = "sum_payment_value",border.alpha = 0)
```

Tak jak z ilością customerów, duża korelacja po prostu z gęstością zaludnienia, raczej do wyrzucenia 

#### Product categories

In the table .., summary statistics about product categories are presented. The most popular category, "bed, bath and tables" accounts for 12% of all items bought in the shop. The table is ordered by the percentage of the customers that in first purchase bought particular category, and later decided to buy in the shop for the second time. The difference in the percentages is clearly visible. For "the best" category, it is 13.8%, while fot the worst one - only 0.029. This is a very promising result, and a signal that the dummy variables indicating product category can serve as important features in the modeling phase. 

```{r}
to_model_train %>%
  select_at(vars(starts_with('prod_cat'), if_second_order)) %>%
  group_by(if_second_order) %>%
  summarise_if(is.numeric, mean) %>%
  filter(if_second_order =='yes') %>%
  pivot_longer(2:16) %>%
  select(-if_second_order) %>%
  mutate(category = str_replace(name, 'prod_cat_', '')) %>%
  rename(percent_second_order = value) %>%
  select(category, percent_second_order) -> product_categories_temp2

to_model_train %>%
  select_at(vars(starts_with('prod_cat'), if_second_order)) %>%
  # nie wiem dlaczego ale niektóre prod categories nie byłY 0,1
  mutate_if(is.numeric, function(x) ifelse(!(x %in% c(0,1)), 1, x)) %>% 
  summarise_if(is.numeric, sum) %>%
  pivot_longer(1:15) %>%
  mutate(category = str_replace(name, 'prod_cat_', '')) %>%
  rename(no_items = value) %>%
  mutate(percentage = no_items/sum(no_items)) %>%
  select(category, no_items, percentage) -> product_categories_temp1

product_categories_temp1 %>%
  left_join(product_categories_temp2) %>%
  arrange(-percent_second_order) %>%
  mutate_if(is.numeric, round,3) %>%
  flextable::flextable() %>%
  flextable::set_caption("Product categories") %>%
  flextable::font(fontname = 'Times New Roman', part = 'all') %>%
  flextable::fontsize(size = 12) %>%
  flextable::autofit()

```

