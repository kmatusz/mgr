---
title: "Dataset description"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = F, warning = F, echo=T, fig.width = 6, fig.height = 4)
```

## Olist

TODO: Opis firmy w oderwaniu od datasetu, zamienić podpunkty na paragraf

- (https://www.kaggle.com/olistbr/brazilian-ecommerce access 14.03.2020)
- Brazilian company
- The dataset was published by the company for public use
- Contains information about 100 thousand orders made on the e-commerce shop site from 2016 to 2018
- Very rich dataset - contains information about the order, customer and review

In particular, there were 96180 transactions (96%) from the customers that never previously bought in this shop. 

In this study I am mostly interested in analysing these transactions, and trying to predict just after first transaction, if the customer is likely to buy second time. Changing the customer attitude after buying for the second time is out of the scope of this study. One reason is the lack of data to properly conduct modeling. The other is that usually making customer buy for the second time is the hardest. In particular in this e-commerce store, in the group of the customers that bought for the first time, only 3.2% of them will buy for the second time. However, in the group of the customers that already bought for the second time, 8.6% will buy third time. The same measure is 18.7% for going from third to fourth time. This is a proof that the very first step of retaining the customer is the most important one, and further it is easier and easier to stop the churn.

The primary key in the dataset in the case of almost all features is order number. However, as in the final dataset I'm including the full information only about the first order of each customer, one observation is equal both to one order and one customer. 

The Olist dataset has the following features groups:

- payment value transportation value - value of the order in Brazilian Reals excluding the transportation cost
- number of items the customer bought in particular order
- review of the order - after the finished order the customer can provide the review of the order in 2 forms - 1-5 score or textual review. In the dataset codebook the authors stated that not all of the customers in real life put any review, but this dataset was sampled in such a way that the records without 1-5 review were excluded. On the contrary, the textual review is filled only in ~50%. The data about 1-5 review can be included to the models as-is. Textual review requires however more intense preprocessing, which is described in the *methods* section of this study.
- location of the customer - the main table containing customer information contains 5-digit ZIP code of the customer's home. The company provided also a mapping table, in which each ZIP code is assigned to multiple latitude/longitude coordinates. Probably this was done because of anonimisation reasons - so that one cannot connect the customer from the dataset with the exact house location. To obtain an exact one-to-one customer-geolocation mapping, to each zip code, I have assigned the most central geolocation from the mapping table. To obtain the most central point, I have used Clustering Around Medoids algorithm with only one cluster, and ran the algorithm separately for each ZIP code. 
- products bought - the dataset contains information about how many items there were in the package, as well as product category of each item - in the form of raw text. In total there were ... categories, but the top .. accounted for ... of all the purchases. To limit the number of the variables for the modeling process, I have decided to change the label of all the least popular categories to "others".

## SIDRA

The dataset about the population statistics was obtained from Instituto Brasileiro de Geografia e Estatística web service called SIDRA (https://sidra.ibge.gov.br/tabela/3548 access 26.09.2020). In this study I have used the data obtained from 2010 general census. The dataset is avaliable in aggregation to microregions (a Brasilian administrative unit, it has similar level of aggregation to NUTS 3 european classification). 558 microregions were avaliable. In particular, I have chosen the following 36 variables from the dataset:

- total population of the microregion - 1 variable
- age structure - percentage of people in particular age bin (with the width of the bins equal to 5 years) - 20 variables
- percentage of people living in rural areas and urban areas - 2 variables
- percentage of immigrants compared to total microregion population - 1 variable
- earnings structure - share of the people that earn between x0\*minimum_wage and x1\*minimum_wage - 11 variables

## Joining of the 2 data sources

Joining of the data coming from SIDRA and OLIST sources proved to be challenging. There were multiple reasons for that:

- In e-commerce dataset the spatial dimansion is decoded mainly in a form of ZIP codes, while in demographic dataset - in a form of microregions.
- The boundaries of zipcodes and microregions do not align.
- The geoloacation data from OLIST has 3 columns - zip code and lat/lng coordinates. For each zip code are multiple entries for coordinates. This probably means that the company has exact coordinates of each of their customers, but decided to not provide exact customer-location mapping in public dataset for anonimisation reasons. Because of that the boundaries of zip codes cannot be specified exactly and one has to rely on the particular points from this zipcode area.

My approach was as follows: 

1. For each of the points in OLIST geolocation dataset, establish in which microregion it is. Join the dataset for that region to OLIST geolocation dataset.
2. Group the dataset by zip code and calculate the mean of each of the features in the dataset. In this case this mean would be a weighted mean (with weight in form of "how many customers are in this area?")

![](resources/11_spatial_join_excel.png)

(TODO: Zrobić tabelki w R a nie w excelu, pewnie też lepiej opisać)


## EDA

```{r }
library(readr)
library(tidyverse)
library("leaflet")
library(psych)
library(lubridate)
library(cluster)
library(factoextra)
library(caret)
library(rpart)
library(DALEX)
library(stringr)
library(sf)
library(tmap)
library(here)
```

```{r cache=T}
load(here('run_all_models_cache/to_model_train.Rdata'))
load(here('run_all_models_cache/to_model_test.Rdata'))
  
vars_basic <- c("payment_value", "review_score", "geolocation_lat", 
                "geolocation_lng",
                "no_items", "sum_freight")

df <- to_model_train[c(vars_basic, 'if_second_order')]
```

#### if_second_order 

TODO: wkleić te info gdzieś do tekstu o sidra

- że 97% (?) klientów nie kupuje drugi raz
- że 50% klientów kupuje max do miesiąca po ostatnim zakupie (tabela z kwantylami?)


#### Payment value

On the plot ... the values of payment for each order are presented.  I have used the Kernel Density Estimation technique to smoothen the plot. As the distribution is highly right-skewed, I have logarithmed the values. The density plot is grouped by the fact whether the particular customer also created a second order later. It can be seen that the 2 densities almost overlap. This means that payment value would not be a good predictor in an univariate approach - although maybe it can be interacted with other features and start having predictive power.


```{r cache=T}
df %>% 
  ggplot(aes(x =payment_value, fill= if_second_order)) +
  geom_density(alpha=0.5) +
  scale_x_log10()
```

#### Review score

On the plot .. percentages of orders that were given x stars in the review are shown. On the right subplot percentages of the customers that made a second order are presented. Most of the reviews are positive - the scores 4 and 5 make up for 75% of the whole dataset. Another thing worth noticing is the tendency to the negative score polarization - if the customer is unsatisfied with the order, it is more likely for her to give the lowest review. 

The Relationship between making a second order and review score for the first one is somehow surprising. One would expect that if the client is unsatisfied for the first time, she will never buy in this store again. In the case of this dataset it is the opposite - the customers that gave one-star review are also the most likely to make the second order. It is worth noting is that the differences between the groups are very small - between 2.9% for review 4 (smallest one), and 3.45% for review 1. One can wonder if this can come simply from random reasons, and that the review score does not influence the probability to come back at all. In particular, the difference between the percentages for the scores 1 and 5 (0.003%) is that small that it most likely for random reasons.

One should bear in mind that the observations avaliable in the dataset are not the complete customers data that the Olist company has. Rather, they were somehow sampled. The dataset authors claim that it represents the customers base in a complete manner. However, there was some sampling bias introduced while creating the dataset that is based on the value of the review score. Namely, in real life case customers do not have to provide star review of every order. The authors of the dataset sampled the orders database in such a way that they excluded the orders, for which the review was not given. One should bear in mind that the analysis of review score is incomplete because of that - one would wonder if there are factors that influence the customer to provide the review, and the very fact of providing the review changes the probability to buy for the second time for that particular customer.

```{r cache=T}

df %>%
  filter(if_second_order=='yes') %>%
  group_by(review_score) %>%
  tally(name = 'cnt_second_order') -> tmp1


ggplot(df, aes(x = review_score)) +
  geom_bar(aes(y = (..count..)/sum(..count..))) +
  labs(y = 'Percentage') + coord_flip() -> pl1


df %>% 
  group_by(review_score) %>%
  tally() %>%
  left_join(tmp1) %>%
  mutate(percent_second_order = cnt_second_order/n) %>%
  ggplot(aes(x = review_score, y = percent_second_order)) +
  geom_col() +
  coord_flip() -> pl2

gridExtra::grid.arrange(pl1, pl2, ncol=2)


```

#### Items - numbers and percentage

On the plot .. analysis of number of items in the order is presetned. There were also orders with number of items above 6, however they make up for 0.2% of the dataset only, that is why I excluded them for clarity of the plot. On the left subplot is shown the percentage share in the full dataset, while on the right one - percentage of the customers that put second order after ordering x items for the first time.

A trend is clearly visible - the more items the customer has bought in the first order, the more likely she is to also put the second order. This difference is pretty strong - between 1 and 6 items the percentage increase in the response is almost 150%. However, one should bear in mind that big orders are extremely rare - 93% of the customers buy one or two items only. 

```{r cache=T}
# less than 7 - 99.7% of orders
ggplot(df %>% filter(no_items<7), aes(x = no_items)) +
  geom_bar(aes(y = (..count..)/sum(..count..))) +
  labs(y = 'Percentage') +
  scale_x_reverse()+
  coord_flip() -> pl1

df %>%
  filter(if_second_order=='yes') %>%
  group_by(no_items) %>%
  tally(name = 'cnt_second_order') -> tmp2

df %>% 
  group_by(no_items) %>%
  tally() %>%
  left_join(tmp2) %>%
  mutate(percent_second_order = cnt_second_order/n) %>%
  filter(no_items<7) %>%
  ggplot(aes(x = no_items, y = percent_second_order)) +
  geom_col() +
  scale_x_reverse()+
  coord_flip() -> pl2

gridExtra::grid.arrange(pl1, pl2, ncol=2)


```

#### Transportation cost  

Sum of the final transportation costs that the customer had to make. The distribution is highly right-skewed, so for clarity I have log-transformed the values. 

No clear distinction between two groups of observations are apparent. 

An interesting thing to check is the relationship between the value of the ordered products and the transportation cost. Pearson correlation between these two is 0.5, meaning that the value of the items ordered somehow influences the rest of the costs.

```{r cache=T}
df %>% 
  ggplot(aes(x = sum_freight, fill=if_second_order)) +
  geom_density(alpha=0.5) +
  scale_x_log10()
```

#### Geolocation

TODO: Opisać mapę, do zastanowienia czy taka mapa pokazuje cokolwiek czy lepiej zbinować punkty do siatki i policzyć procentowy udział 


```{r cache=T}

tmap_mode("plot")
brazil_map <- brazilmaps::get_brmap("Brazil")

df = df[df$geolocation_lat <= 5.27438888,]
df = df[df$geolocation_lng >= -73.98283055,]
df = df[df$geolocation_lat >= -33.75116944,]
df = df[df$geolocation_lng <=  -34.79314722,]


df_map <- sf::st_as_sf(df %>% sample_n(10000), coords = c(4,3))
df_map <- sf::st_as_sf(df, coords = c(4,3))
st_crs(df_map) <- st_crs(brazil_map)

df_map %>%
  mutate(size=ifelse(if_second_order=='yes', 1, 0.4)) -> df_map
```


```{r cache=T}
tm_shape(brazil_map) +
  tm_polygons(col = "white") +
  tm_shape(df_map %>% filter(if_second_order!='yes')) +
  tm_symbols(size = 0.1,
             col = "if_second_order",
             palette = RColorBrewer::brewer.pal(3, 'Dark2')[1:2],
             # palette = c('red', ''),
             # style = "fixed",
             # breaks = c(45, 60, 75, 90),
             border.lwd = NA,
             alpha = 0.5)+
  tm_shape(df_map %>% filter(if_second_order=='yes')) +
  tm_symbols(size = 0.1,
             col = "if_second_order",
             palette = RColorBrewer::brewer.pal(3, 'Dark2')[2],
             # palette = c('red', ''),
             # style = "fixed",
             # breaks = c(45, 60, 75, 90),
             border.lwd = NA,
             alpha = 0.5)
```

#### Product categories (TODO)

TODO: tabela: kategoria, liczba obserwacji dla kategorii, procentowy if_second_order



