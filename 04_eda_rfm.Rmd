---
title: "Clustering analysis of customers dataset"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(message = F, warning = F)
```


```{r }
library(readr)
library(tidyverse)
library("leaflet")
library(psych)
library(lubridate)
library(cluster)
library(factoextra)
library(fpc)

orders <- read_csv("data/olist_orders_dataset.csv")
customers <- read_csv("data/olist_customers_dataset.csv")
geolocation <- read_csv("data/olist_geolocation_dataset.csv")
order_items <- read_csv("data/olist_order_items_dataset.csv")
order_payments <- read_csv("data/olist_order_payments_dataset.csv")
order_reviews <- read_csv("data/olist_order_reviews_dataset.csv")
products <- read_csv("data/olist_products_dataset.csv")
sellers <- read_csv("data/olist_sellers_dataset.csv")
product_translation <- read_csv("data/product_category_name_translation.csv")
```

First approach to clustering is with using Recency, Frequency and Moneatary value features.

Definition of RFM:
Recency - how many days ago the last order by the particular customer was placed?
Frequency - how many orders did particular customer placed in all his history?
monetary value - how much money did particular customer pay in all his history?

```{r }
order_payments %>%
  group_by(order_id) %>%
  summarise(payment_value = sum(payment_value)) -> order_payments_agg


orders %>%
  select(order_id,
         customer_id,
         order_purchase_timestamp) %>%
  left_join(order_payments_agg, by = c('order_id'='order_id')) %>%
  left_join(customers %>% select(customer_id, customer_unique_id)) %>%
  select(5,1,3,4) -> df

ggplot(df, aes(x = order_purchase_timestamp)) +
  geom_histogram()
```

Orders in the dataset are mostly from 01.2017 to 10.2018 - 
there is a small amount at the end of 2016, but it looks like it shouldn't be there. 
We can drop it as it won't affect the count largely.
This code is prepared to move the window of the analysis - to change the date of the clustering.

```{r }
df %>%
  filter(dmy('01-01-2017') < order_purchase_timestamp, 
         order_purchase_timestamp < dmy('18-10-2018')) -> df_to_date
```


Calculating RFM measures (due to the date computation it can take a while):

```{r }
# df_to_date %>%
#   group_by(customer_unique_id) %>%
#   summarise(
#     most_recent = max(order_purchase_timestamp),
#     rec = as.numeric(difftime(dmy('18-10-2018'), most_recent, units = 'days')),
#     fre = n(),
#     mon = sum(payment_value, na.rm = T)
#     ) -> df_rfm
# save(df_rfm, file='data/04_df_rfm.Rdata')
load('data/04_df_rfm.Rdata')
df_rfm %>%
  summary()
```

very large skew visible in fre and mon variables.

```{r }
df_rfm %>% 
  select(-customer_unique_id, -most_recent) %>%
  GGally::ggpairs()
```

Here the skew is even more visible. K-means can't accept such non-spherical data. 
Monetary value can be log-transformed, and frequency encoded as categorical variable - 
if more than one purchase.

```{r }
df_rfm %>%
  mutate(fre = ifelse(fre==1, 0,1)) %>%
  mutate(
    mon = ifelse(mon>0, log(mon), 0)
  ) %>%
  select(rec, fre, mon) %>%
  mutate_at(c('rec', 'mon'), ~(scale(.) %>% as.vector))-> df_rfm_scaled

df_rfm_scaled

df_rfm_scaled %>% 
  GGally::ggpairs()
```

As freqency is now categorical variable with 2 levels, we can split the dataset based on it: 

```{r }
df_rfm_scaled %>%
  ggplot(aes(x = rec, y = mon)) +
  geom_point(alpha=0.5) +
  facet_grid(rows = vars(fre))
```

Nothing particularly interesting is visible here. Recency has a distribution close to uniform,
and monetary value after logarithminc transformation got close to normal distribution. 
Now I am going to test clustering tendency using Hopkins statistic:

```{r }
df_rfm_scaled %>%
  sample_n(200) %>%
  get_clust_tendency(n=199)
```

Hopkins statistic is 0.75, meaning that the dataset is clusterable. 

Same statistic, but applied only on frequent customers:

```{r }
df_rfm_scaled %>%
  filter(fre==1) %>%
  sample_n(400) %>%
  get_clust_tendency(n=399)
```

Hopkins statistic is 0.67, meaning that the dataset is clusterable.
Testing correct number of clusters for loyal customers:

```{r }
factoextra::fviz_nbclust(df_rfm_scaled %>%
                           filter(fre==1) %>%select(-fre), FUNcluster = kmeans)
```

2 clusters are optimal - but silhouette value is not very good. Running kmeans with that value:

```{r }
km <- kmeans(df_rfm_scaled %>%
               filter(fre==1) %>%
               select(-fre), 
             centers = 2
             )

fviz_cluster(km, 
             data = df_rfm_scaled %>%
               filter(fre==1) %>%
               select(-fre),
             geom = 'point')

```

The dataset is cut in half based on frequency value.

```{r }
silhouette(km$cluster, 
           dist(df_rfm_scaled %>%
                  filter(fre==1) %>%
                  select(-fre)))-> sil

fviz_silhouette(sil)
```

Average silhouette is 0.37. This result is not so great. 

Now, I am trying to fit dbscan algorithm - as a more flexible alternative to kmeans.

```{r }
library(dbscan)
dbscan::kNNdistplot(df_rfm_scaled %>%
                      filter(fre==1) %>%
                      select(-fre), k =  5)
abline(h=0.25)
```


For 5 customers as minimum amount in the cluster, 
distance chosen by the elbow method is 0.25 

```{r }
res.db <- dbscan::dbscan(df_rfm_scaled %>%
                           filter(fre==1) %>%
                           select(-fre), 0.25, 5)

fviz_cluster(res.db, df_rfm_scaled %>%
               filter(fre==1) %>%
               select(-fre), geom = "point")
```

Almost all points were assigned to one big cluster - nothing interesting is visible here.

Clustering using RFM variables did not give any promising results. However,
 there are also other variables in the dataset, that could give better results.
 Below, I have analyzed geolocation data in search for good clustering. 
 First, data preparation:

```{r }
customers %>%
  left_join(geolocation %>% 
              group_by(geolocation_zip_code_prefix) %>%
              filter(row_number()==1) %>%
              ungroup() %>% select(1,2,3) %>% distinct(),
            by = c('customer_zip_code_prefix' = 'geolocation_zip_code_prefix')) %>%
  select(geolocation_lng, geolocation_lat) %>%
  filter(geolocation_lat<20, geolocation_lng< -20) %>%
  sample_n(1000) %>%
  scale-> a
```

Now, checking the best number of clusters:


```{r }
factoextra::fviz_nbclust(a, FUNcluster = kmeans)
```

Best number of clusters judging by silhouette is 2. 
However, clustering with more centers also looks promising.

```{r }
kmeans(a, centers = 2) %>%
  fviz_cluster(a, geom = 'point')
```

The two clusters more or less divide the country in southern and northern part. 
This has its explanation - southern part of Brazil is way more industrialized and urbanized.

Now, checking DBSCAN:
  

```{r }
library(dbscan)
dbscan::kNNdistplot(a, k =  3)
abline(h=0.45)
```


For 5 customers as minimum amount in the cluster, 
distance chosen by the elbow method is 0.45 

```{r }
res.db <- dbscan::dbscan(a, 0.24, 3)

res.db

fviz_cluster(res.db, a, geom = "point")
```

To summarise, RFM variables have not shown a potential for clustering. 
However, as a proof of concept, geolocation variables did, and because of that the idea
witch clustering is still worth exploring.
